1. Pandas - This is one of the open-source Python libraries which is mainly used in Data Science and machine learning subjects. 
			This library mainly provides data manipulation and analysis tool, which are used for analyzing data using its powerful 
			data structures for manipulating numerical tables and time series analysis.

2. NumPy - NumPy is another library that is used for mathematical functions. The NumPy library is popular for array and matrix processing using a set of mathematical functions.  
			This library is mostly used in machine learning computations.
			
3. Requests - This is another different library module in Python used for sending HTTP requests and supports functionalities like adding headers,
			  the formation of data, and accessing responsive data objects, which include content data, encoding data, status, etc.
			  
4. SciPy - In Python, the scipy library is one of the open-source libraries mainly used in mathematical and scientific computations, 
			technical and engineering computations. It is mainly built on NumPy.
			
5. Sqllite3 - Python programming language provides a library for database operations. This library is mainly used for database operations using sql queries.

6. TensorFlow - This library was developed by Google in collaboration with the Brain Team. It is an open-source library used for high-level computations. 
				It is also used in machine learning and deep learning algorithms. It contains a large number of tensor operations. 
				Researchers also use this Python library to solve complex computations in Mathematics and Physics.
				
7. Matplotlib - This library is responsible for plotting numerical data. And that’s why it is used in data analysis. 
				It is also an open-source library and plots high-defined figures like pie charts, histograms, scatterplots, graphs, etc.
				
8. Scrapy - It is an open-source library that is used for extracting data from websites. It provides very fast web crawling and high-level screen scraping. 
			It can also be used for data mining and automated testing of data.
			
9. Scikit-learn - It is a famous Python library to work with complex data. Scikit-learn is an open-source library that supports machine learning. 
				  It supports variously supervised and unsupervised algorithms like linear regression, classification, clustering, etc.
				  This library works in association with Numpy and SciPy.
				  
10. PyGame - This library provides an easy interface to the Standard Directmedia Library (SDL) platform-independent graphics, audio, and input libraries. 
			 It is used for developing video games using computer graphics and audio libraries along with Python programming language.
			 
11. PyTorch - PyTorch is the largest machine learning library that optimizes tensor computations. It has rich APIs to perform tensor computations with strong GPU acceleration. 
			  It also helps to solve application issues related to neural networks.
			  
12. PyBrain - The name “PyBrain” stands for Python Based Reinforcement Learning, Artificial Intelligence, and Neural Networks library. 
			  It is an open-source library built for beginners in the field of Machine Learning. It provides fast and easy-to-use algorithms for machine learning tasks. 
			  It is so flexible and easily understandable and that’s why is really helpful for developers that are new in research fields.
			  
13. Flask - Flask is a fast-growing web framework, designed for a more efficient API designing process. Well, this is only one of the possible usages of Flask.
			In general, it is a framework for web application development.
			Flash is lightweight, offers support for unit testing and secure cookies for client-side sessions.
			Developers praise this framework for being well-documented, meaning that you will find many use cases to learn.

14. EVE - Eve is a free Python-based REST API framework, powered by Flask and Cerberus.
		  It allows a speedy development of unique, feature-rich RESTful web services.
		  The framework supports MongoDB and is highly compatible due to extensions.

15. Falcon - Falcon is a lightweight, SWGI-compliant web framework, designed for building RESTful APIs.
			 Beginners appreciate the well-documented tutorials that provide plenty of guidance for the first project creation.
			 The Falcon runs on any hardware and relies only on two third-party dependencies.

16. Theano - Theano is a Python-based library for performing mathematical operations to multi-dimensional arrays.
			 The framework uses GPU instead of the CPU, which leads to higher productivity levels.
			 With Theano, developers create deep learning models or wrapper libraries.
			 Another advantage is the framework’s capability of managing types of computation necessary for large neural network algorithms.

17. Keras - Keras is a Python-based library for developing deep learning models.
			It is compatible with other Python libraries as well (TensorFlow or Theano too).
			The main purpose of this framework is the quick prototyping of neural networks.
			Developers can experiment with deep neural networks and train them.

18. BeautifulSoup - It is a web scraping library that is used to get data from HTML and XML files. It is a great tool for beginners interested in extracting 
				    data as it represents the data. In the information in the form of a parse tree which is human readable. It is also easy to navigate, 
					search and modify the parse tree.
					Other modules which we can refer to for web scraping are Scrapy and Selenium.
					
19. Tkinter - This is a library that helps in developing an app with a Graphical User Interface (GUI). This is one of the most commonly used frameworks by 
			  developers for creating GUIs. It connects Python to the TK GUI toolkit, which virtually works on every modern operating system.
			  Another module that can be used for this purpose is PyQt that binds Python with a cross platform toolkit named Qt.
			  
20. Pillow - If you are interested in image processing then PIL or Pillow is a must-have Python library. It provides simple and easy-to-use commands to open, 
		     manipulate, and save different image file formats. It is a good place to start for a beginner.
			 To go deep into it, one can choose OpenCv that helps us to perform complex image processing algorithms.
			 
21. SQLAlchemy - SQLAlchemy is a library designed for accessing databases. It allows us to form a connection between Python and the database. 
				 It provides easy-to-understand commands that can be used by beginners too. This library of Python supports most platforms which include 
				 Python 2.5, Jython, and Pypy.
				 Other libraries that can be used are SQLite and mysql-connector.
22. PyWin32 - For the programmer using Windows, Pywin32 is a package that they must know. It provides methods and classes for interacting with Windows.
			  PyWin32 provides access to many of the native Windows API functions. It allows you to interact with the Windows registry, use the Windows clipboard, and so on.
			  
23. XGBoost - XGBoost stands for extreme gradient boosting. This Python AI library focuses on helping developers classify data and build regressions 
			  using boosted decision-tree algorithms. These trees are made up of children of weaker regression models (that represent different computation tasks). 
			  As the model is trained, new weaker regression models are added to “fill in the gaps” until no further improvements can be made. 
			  By doing this, XGBoost greatly increases scalability and performance; perfect for keeping up with your program’s growth.
Matplotlibhttps://matplotlib.org/Matplotlib allows developers to visualize datasets with a variety of different charts. It’s best used to discover and present insights on processed data. Whether it’s by using a static, dynamic or an interactive graph, matplotlib brings your data to life and is important for communication with non-technical audiences.

Natural Language Processing
Natural language processing brings all aspects of linguistics to a computer program. Its ultimate goal is primarily to understand and communicate to humans and other machines. And that’s not as simple as it sounds. There are a lot of rules and hidden information that need to be explicitly taught to machines. To bridge the gap between humans and machines, NLP uses syntactic and semantic analysis to form sentences correctly and extract meaning from them.
Everything that you communicate with using human language that isn’t a human likely uses some level of NLP. Some examples are chatbots, writing analytics tools (such as Grammarly) and smart assistants in your phones and homes.

NLTK
http://www.nltk.org

NLTK stands for Natural Language Toolkit. It’s a Python AI library that makes trivial linguistics simple through a variety of defined functions and interfaces. From tokenizing and tagging text, to identifying named entities and even displaying parse trees, NLTK is a general-purpose NLP library (or ‘toolkit’) that belongs in any language-based project.

spaCy
https://spacy.io/

spaCy has been described by its developers as “the Ruby on Rails of Natural Language Processing.” Indeed, through its extremely simple API, spaCy makes processing large swathes of text fast and efficient. By providing and integrating tokenizer, tagger, parser, pre-trained word vectors and named entity recognition facilities into one library, spaCy can help your program understand all aspects of a text, or simply pre-process it for one of the other AI libraries to deal with later.

Gensim
https://radimrehurek.com/gensim/

Gensim aims to make the process of identifying the underlying topic of a piece of text (known as topic modeling) substantially easier. It handles the entire modeling process, from processing the text (into a dictionary of tokens) to building the topic model itself all without having to load the entire text into memory.

Neural Networks
Neural networks allow programs to literally use their brains. They use systems of nodes (modeled after the neurons in human brains) with each node representing a particular variable or computation. A particular task (where we need to map an input to a particular output) starts at one input “neuron” (or layer) in the system and can get to the end, processed result (or output) by taking any number of pathways (computations). The pathways that lead to a more successful/closer mapping to the output are strengthened and kept while failing/inaccurate pathways are weakened and discarded. And this is precisely how our brain works. It makes for an incredibly efficient form of learning.
Neural networks can allow us to implement facial recognition algorithms, predict the weather more effectively or even simulate marketing campaigns for businesses.

FANN
https://github.com/libfann/fann

Fast Artificial Neural Network Library, or FANN, implements artificial neural networks in C (which is what makes it up to 150 times faster than other libraries) while making them accessible in a number of different languages, including Python. It’s incredibly easy to use, allowing for the creation, training and running of an artificial neural network in just three function calls. With its incredible documentation, comprehensive training framework and parameter versatility, it’s a must-have for a project which employs neural networks.

ffnet
https://github.com/mrkwjc/ffnet

ffnet is a Python AI library for implementing feed-forward neural networks. It uses a graphical user interface to visualize training datasets. Another strong benefit is its automatic data normalization feature, saving a lot of time in the pre-processing stage of your workflow. Ffnet implements its core functions in Fortran resulting in greatly improved program speed (compared to Python native solutions).

PyTorch
https://pytorch.org/

PyTorch is built for tensor computation tasks (using GPU acceleration) and building more durable deep neural networks on a tape-based autograd system. The last point means that the neural networks PyTorch builds don’t have to be recreated every time the use case changes, thereby improving speed and scalability. Its main use cases lie in replacing NumPy to instead use the power of GPUs (versus CPUs), and as a deep learning research platform that is highly customizable and fast.

Computer Vision
Like the name suggests, computer vision allows machines to both see and understand what they’re seeing. Through videos and images, machines can figure out what objects they’re looking at and classify them into appropriate categories. That smart CAPTCHA software you see barring you entry to your favorite website is actually getting you to train its computer vision algorithm for it. From facial recognition software to autonomous driving systems, computer vision algorithms are everywhere and only growing in complexity.

OpenCV
https://opencv.org/

Open Source Computer Vision Library (OpenCV) provides developers with over 2,500 optimized algorithms for a variety of computer vision use cases. From detecting/recognizing faces to classifying human actions, OpenCV makes understanding visual information a simple matter of calling the right function and specifying the right details. Paired with its robust community and extensive documentation, OpenCV is perfect for adding computer vision infrastructure to a project.

SimpleCV
http://simplecv.org/

Where OpenCV focuses on comprehensiveness and customizability, SimpleCV focuses on making computer vision easy. The learning curve is much smaller to the point where getting images from a camera is as simple as initializing a camera (using Camera()) and getting its image (using Camera.getImage()). This Python AI library is a stellar choice for developers focused on common computer vision applications as opposed to highly customized solutions.

Expert Systems
Want the advice of an expert? You can ask one (for a price) or you can get a machine to think like an expert for you. As their name suggests, expert systems aim to model an expert’s reasoning process using a knowledge base (heaped with relevant data), an inference engine (to reason based on the data), and an explanation interface (to communicate its reasoning to the user).
So experts such as doctors and engineers can diagnose the type and degree of lung cancer in patients (PXDES) or construct computer systems based on user preferences (R1/XCON). 

PyCLIPS
http://pyclips.sourceforge.net/web/

PyCLIPS provides an inference engine to Python applications. It provides a rules-based engine as binary modules inside the library that are accessed using classes and functions. The engine itself stays “alive” in a separate memory space to the Python space, so inferences and rules are persisted as your program grows in functionality.

Experta
https://pypi.org/project/experta/

Also inspired by CLIPS, Experta is a rule engine that pairs a set of facts with a set of rules based on those facts. Then, actions are executed based on these rules. All facts and rules are held by the implemented knowledge engine which determines the expert output of the system when it is called.

Robotics and Autonomous Vehicles
Most artificial intelligence is usually applied to software, not hardware. With robotics, AI meets the physical world through a plethora of different sensors modeling the human senses. From cameras to model sight and radar to model physical touch, AI algorithms must interpret the data from these sensors to allow a machine to function safely and effectively.

AirSim
https://github.com/Microsoft/AirSim

AirSim is a Unity/Unreal Engine based simulator built by Microsoft. While it’s not a Python AI library itself, AirSim allows developers to test and experiment with autonomous vehicle algorithms without actually needing to possess the physical hardware for it. It uses APIs to hook into your code so it remains language independent. In this way, it provides a sandbox for you to play around with autonomous vehicles without the costs and safety issues you’d need to overcome in the real, physical world.

Carla
https://github.com/carla-simulator/carla

Where AirSim can cater to a wide variety of autonomous vehicles (such as cars and drones), Carla caters specifically to autonomous driving research. It has more driver-specific features like flexible vehicle sensors, environmental conditions as well as a wide variety of buildings and vehicles already implemented.

Bullet 
https://github.com/bulletphysics/bullet3

Bullet provides a physics sandbox where robotics/virtual reality can be created and tested. This allows the development of capital-intense development tasks like collision detection, locomotion skills and reinforcement learning (which requires a lot of failure) to be conducted in a harmless simulation scenario.